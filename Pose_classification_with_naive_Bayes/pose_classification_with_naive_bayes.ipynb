{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2021 Semester 1\n",
    "\n",
    "## Assignment 1: Pose classification with naive Bayes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Student ID(s):**     `1182728`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iPython notebook is a template which you will use for your Assignment 1 submission.\n",
    "\n",
    "Marking will be applied on the four functions that are defined in this notebook, and to your responses to the questions at the end of this notebook (Submitted in a separate PDF file).\n",
    "\n",
    "**NOTE: YOU SHOULD ADD YOUR RESULTS, DIAGRAMS AND IMAGES FROM YOUR OBSERVATIONS IN THIS FILE TO YOUR REPORT (the PDF file).**\n",
    "\n",
    "You may change the prototypes of these functions, and you may write other functions, according to your requirements. We would appreciate it if the required functions were prominent/easy to find.\n",
    "\n",
    "**Adding proper comments to your code is MANDATORY. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads the data from a file and converting it into a dictionary of class:attributes \n",
    "# drop the instance if all attributes are missing \n",
    "\n",
    "def preprocess(filename):\n",
    "    f = pd.read_csv(filename, na_values = \"9999.0000\", header = None)\n",
    "    \n",
    "    # delete instances with all missing values\n",
    "    f = f.dropna(axis=0, how='all', subset = [i for i in range(1, f.shape[1])])\n",
    "    \n",
    "    # convert the format of the data into a dictionary \n",
    "    data = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(f)):\n",
    "        data[list(f.iloc[i])[0]].append(list(f.iloc[i])[1:])\n",
    "   \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculates prior probabilities and likelihoods from the training data and using them to build a naive Bayes model\n",
    "\n",
    "def train(train_data):\n",
    "    \n",
    "    # the total number of attribtues in training data\n",
    "    total_num = sum([len(train_data[i]) for i in train_data.keys()])\n",
    "    \n",
    "    # the prior possibility of each class \n",
    "    prior_class = []\n",
    "    \n",
    "    # a dictionary containing the mean and sd of each attribute from each class \n",
    "    stats = defaultdict(list)\n",
    "    \n",
    "    for i in train_data.keys():\n",
    "        \n",
    "        # compute the priors for each class \n",
    "        prior_class.append(len(train_data[i])/total_num)\n",
    "        \n",
    "        # compute the mean and standard deviations, ignoring missing values \n",
    "        stats[i].append(np.nanmean(train_data[i], axis = 0))\n",
    "        stats[i].append(np.nanstd(train_data[i], axis = 0))\n",
    "\n",
    "    return (stats, prior_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts classes for new items in a test dataset \n",
    "def predict(stats, priors, test_file):\n",
    "\n",
    "    f = pd.read_csv(test_file, na_values = \"9999.0000\", header = None)\n",
    "    \n",
    "    y_test = list(f[0])\n",
    "    \n",
    "    # distinct classes \n",
    "    classes = list(stats.keys())\n",
    "\n",
    "    pi = [math.sqrt(2*math.pi)] * (f.shape[1]-1)\n",
    "    \n",
    "    # predicted labels and results\n",
    "    labels = []\n",
    "\n",
    "    # for each row in the data \n",
    "    for i in range(f.shape[0]):\n",
    "        \n",
    "        # compute log(prior_possibilities)\n",
    "        prior = np.log(priors)\n",
    "        \n",
    "        # a list of attribute values\n",
    "        attr = list(f.iloc[i])[1:]\n",
    "        \n",
    "        # a 1d array containing the likelihoods \n",
    "        p_ij = np.zeros(len(classes))\n",
    "        \n",
    "        for j in range(len(classes)):\n",
    "            \n",
    "            c = classes[j]\n",
    "            mean = stats[c][0]\n",
    "            sd = stats[c][1]\n",
    "            \n",
    "            p_xc = 1/(sd * pi) * np.exp(-0.5* np.power((attr - mean)/sd, 2))\n",
    "            p_xc = np.log(p_xc)\n",
    "            \n",
    "            \n",
    "            # a way to deal with zero values\n",
    "            p_xc = np.nan_to_num(p_xc, nan=0.0)\n",
    "            p_ij[j] = np.sum(p_xc)\n",
    "            \n",
    "        sums = prior + p_ij\n",
    "        labels.append(classes[np.argmax(sums)])\n",
    "        \n",
    "    return (y_test, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the prediction performance by comparing your model’s class outputs to ground truth labels\n",
    "\n",
    "def evaluate(y_test, y_pred):\n",
    "    \n",
    "    correct = 0\n",
    "        \n",
    "    for i in range(len(y_test)):\n",
    "        if y_pred[i] == y_test[i]:\n",
    "            correct += 1\n",
    "\n",
    "    total_accuracy = correct / len(y_pred)\n",
    "\n",
    "    return total_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Averaging -> Precision: 0.74, Recall: 0.74, F_Score: 0.74\n",
      "Macro-Averaging -> Precision: 0.74, Recall: 0.72, F_Score: 0.72\n",
      "Weighted-Averaging -> Precision: 0.74, Recall: 0.75, F_Score: 0.74\n",
      "0.74\n"
     ]
    }
   ],
   "source": [
    "# a function that accepts a training file and a testing file, and then returns the accuracy score \n",
    "\n",
    "def GNB(train_file, test_file, extend):\n",
    "    train_data = preprocess(train_file)\n",
    "    stats, priors = train(train_data)\n",
    "    y_test, y_pred = predict(stats, priors, test_file)\n",
    "    \n",
    "    # if we need extended evaluation\n",
    "    if extend:\n",
    "        return evaluate_extend(y_test, y_pred)\n",
    "    \n",
    "    return evaluate(y_test, y_pred)\n",
    "\n",
    "print(GNB(\"train.csv\", \"test.csv\", True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions \n",
    "\n",
    "\n",
    "If you are in a group of 1, you will respond to **two** questions of your choosing.\n",
    "\n",
    "If you are in a group of 2, you will respond to **four** questions of your choosing.\n",
    "\n",
    "A response to a question should take about 100–250 words, and make reference to the data wherever possible.\n",
    "\n",
    "#### NOTE: you may develope codes or functions to help respond to the question here, but your formal answer should be submitted separately as a PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "Since this is a multiclass classification problem, there are multiple ways to compute precision, recall, and F-score for this classifier. Implement at least two of the methods from the \"Model Evaluation\" lecture and discuss any differences between them. (The implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate_extend(y_test, y_pred):\n",
    "    \n",
    "    labels = y_pred\n",
    "    classes = y_test\n",
    "    \n",
    "    n_classes = len(unique_labels(classes))\n",
    "    \n",
    "    # print(confusion_matrix(classes, labels))\n",
    "    \n",
    "    correct =0\n",
    "        \n",
    "    tp = defaultdict(int)\n",
    "    fp = defaultdict(int)\n",
    "    fn = defaultdict(int)\n",
    "    tn = defaultdict(int)\n",
    "    \n",
    "    # compute the metrics for evaluation\n",
    "    for i in range(len(labels)):\n",
    "        \n",
    "        if labels[i] == classes[i]:\n",
    "            tp[classes[i]] += 1\n",
    "            correct += 1\n",
    "        else:\n",
    "            fn[labels[i]] += 1\n",
    "            fp[classes[i]] += 1\n",
    "    \n",
    "    # the weight fractions of each class based on their distribution \n",
    "    weight = defaultdict(float)\n",
    "    \n",
    "    # compute true negatives and weight fractions \n",
    "    for c in tp.keys():\n",
    "        tn[c] = len(labels) - tp[c] - fp[c] - fn[c]\n",
    "        weight[c] = classes.count(c) / len(classes)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    total_accuracy = correct / len(labels)\n",
    "   \n",
    "    precision = defaultdict(float)\n",
    "    recall = defaultdict(float)\n",
    "    f_score = defaultdict(float)\n",
    "    \n",
    "    \n",
    "    for c in tp.keys():\n",
    "        precision[c] = (tp[c]) / (tp[c] + fp[c])\n",
    "        recall[c] = tp[c] / (tp[c] + fn[c])\n",
    "        f_score[c] = (2 * precision[c] * recall[c]) / (precision[c] + recall[c])\n",
    "\n",
    "    \n",
    "    # micro-averaing\n",
    "    total_tp = sum(list(tp.values()))\n",
    "    total_fp = sum(fp.values())\n",
    "    total_fn = sum(fn.values())\n",
    "    total_tn = sum(tn.values())\n",
    "    \n",
    "    micro_precision = total_tp / (total_tp + total_fp)\n",
    "    micro_recall = total_tp / (total_tp + total_fn)\n",
    "    micro_f_score = 2 * micro_precision * micro_recall / (micro_precision + micro_recall)\n",
    "    \n",
    "    print('Micro-Averaging -> Precision: {:.2f}, Recall: {:.2f}, F_Score: {:.2f}'.format(micro_precision,micro_recall,micro_f_score))\n",
    "        \n",
    "    # macro-averaing   \n",
    "    total_precision = sum(list(precision.values())) / n_classes\n",
    "    total_recall = sum(list(recall.values())) / n_classes\n",
    "    total_f_score = sum(list(f_score.values())) / n_classes\n",
    "    \n",
    "    print('Macro-Averaging -> Precision: {:.2f}, Recall: {:.2f}, F_Score: {:.2f}'.format(total_precision,total_recall,total_f_score))\n",
    "    \n",
    "    # weighted averaging \n",
    "    tot_prec = 0.0\n",
    "    tot_recall = 0.0\n",
    "    tot_f = 0.0\n",
    "    \n",
    "    for c in weight.keys():\n",
    "        tot_prec += precision[c] * weight[c]\n",
    "        tot_recall += recall[c] * weight[c]\n",
    "        tot_f += f_score[c] * weight[c]\n",
    "    \n",
    "    print('Weighted-Averaging -> Precision: {:.2f}, Recall: {:.2f}, F_Score: {:.2f}'.format(tot_prec, tot_recall, tot_f))\n",
    "    \n",
    "    total_accuracy = '{:.2f}'.format(total_accuracy)\n",
    "    return total_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "Implement a kernel density estimate (KDE) naive Bayes classifier and compare its performance to the Gaussian naive Bayes classifier. Recall that KDE has kernel bandwidth as a free parameter -- you can choose an arbitrary value for this, but a value in the range 5-25 is recommended. Discuss any differences you observe between the Gaussian and KDE naive Bayes classifiers. (As with the Gaussian naive Bayes, this KDE naive Bayes implementation should be your own and should not just call a pre-existing function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepts a test df and a train df\n",
    "\n",
    "# This function reads the data from a file and converting it into a dictionary of class:attributes \n",
    "# drop the instance if all attributes are missing \n",
    "\n",
    "def preprocess(filename):\n",
    "    f = pd.read_csv(filename, na_values = \"9999.0000\", header = None)\n",
    "    \n",
    "    # delete instances with all missing values\n",
    "    f = f.dropna(axis=0, how='all', subset = [i for i in range(1, f.shape[1])])\n",
    "    \n",
    "    # convert the format of the data into a dictionary \n",
    "    data = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(f)):\n",
    "        data[list(f.iloc[i])[0]].append(list(f.iloc[i])[1:])\n",
    "   \n",
    "    return data\n",
    "\n",
    "\n",
    "# This function calculates prior probabilities and likelihoods from the training data and using them to build a naive Bayes model\n",
    "\n",
    "def train(train_data):\n",
    "    \n",
    "    # the total number of attribtues in training data\n",
    "    total_num = sum([len(train_data[i]) for i in train_data.keys()])\n",
    "    \n",
    "    # the prior possibility of each class \n",
    "    prior_class = []\n",
    "    \n",
    "    # a dictionary containing the mean and sd of each attribute from each class \n",
    "    stats = defaultdict(list)\n",
    "    \n",
    "    for i in train_data.keys():\n",
    "        \n",
    "        # compute the priors for each class \n",
    "        prior_class.append(len(train_data[i])/total_num)\n",
    "        \n",
    "        # compute the mean and standard deviations, ignoring missing values \n",
    "        stats[i].append(np.nanmean(train_data[i], axis = 0))\n",
    "        stats[i].append(np.nanstd(train_data[i], axis = 0))\n",
    "\n",
    "    return (stats, prior_class)\n",
    "\n",
    "\n",
    "\n",
    "def KDE_predict(kernel_bandwidth, stats, priors, test_df, train_data):\n",
    "\n",
    "    kb = kernel_bandwidth\n",
    "    \n",
    "    # target labels of test set\n",
    "    y_test = list(test_df[0])\n",
    "    \n",
    "    \n",
    "    # distinct classes \n",
    "    classes = list(stats.keys())\n",
    "\n",
    "    # arrays used in calculation \n",
    "    pi = np.array([math.sqrt(2*math.pi)] * (test_df.shape[1]-1))\n",
    "    sd = np.array([kb] * (test_df.shape[1]-1))\n",
    "    \n",
    "    # predicted labels and results\n",
    "    labels = []\n",
    "  \n",
    "\n",
    "    # for each test instance \n",
    "    for i in range(test_df.shape[0]):\n",
    "        \n",
    "        # get a list of attribute values of the test instance\n",
    "        attr = np.array(list(test_df.iloc[i])[1:])\n",
    "        \n",
    "        # a 1d array containing the likelihoods of all classes\n",
    "        p_ij = np.zeros(len(classes))\n",
    "        \n",
    "        # for each class, we compute the KDE, with sd = 5 and then add them up, times 1/N \n",
    "        for j in range(len(classes)):\n",
    "            \n",
    "            c = classes[j]\n",
    "            \n",
    "            likelihoods = 0.0\n",
    "            \n",
    "            # for each training instance, compute the likelihood of each class c\n",
    "            for data in train_data[c]:  \n",
    "                data = np.array(data)\n",
    "                data = np.nan_to_num(data, nan=0.0)\n",
    "                \n",
    "                # substitute into the function \n",
    "                k = (1/(pi*sd) * np.exp(-0.5 * np.power((attr-data)/sd, 2)))\n",
    "                k = np.nan_to_num(k, nan=1.0)\n",
    "                \n",
    "                likelihoods += np.prod(k)\n",
    "              \n",
    "            posterior_likelihood = likelihoods * 1/len(train_data[c]) * priors[j]\n",
    "            p_ij[j] = posterior_likelihood\n",
    "\n",
    "        # add the prediction   \n",
    "        labels.append(classes[np.argmax(p_ij)])\n",
    "          \n",
    "    return (y_test, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844827586206896\n"
     ]
    }
   ],
   "source": [
    "# a function used to implement KDE classifier \n",
    "\n",
    "def KDE(train_file, test_file, kernel_bandwidth):\n",
    "    train_data = preprocess(train_file)\n",
    "    stats, priors = train(train_data)\n",
    "    test_df = pd.read_csv(test_file, na_values = \"9999.0000\", header = None)\n",
    "    y_test, y_pred = KDE_predict(kernel_bandwidth, stats, priors, test_df, train_data)\n",
    "    return evaluate(y_test, y_pred)\n",
    "\n",
    "print(KDE(\"train.csv\", \"test.csv\", 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "Instead of using an arbitrary kernel bandwidth for the KDE naive Bayes classifier, use random hold-out or cross-validation to choose the kernel bandwidth. Discuss how this changes the model performance compared to using an arbitrary kernel bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a alternative train(method) for KDE \n",
    "\n",
    "# This function accepts a training dataFrame, and it calculates prior probabilities \n",
    "# and likelihoods from the training data and using them to build a naive Bayes model\n",
    "\n",
    "def KDE_train(train_df):\n",
    "    \n",
    "    train_data = defaultdict(list)\n",
    "    \n",
    "    for i in range(len(train_df)):\n",
    "        train_data[list(train_df.iloc[i])[0]].append(list(train_df.iloc[i])[1:])\n",
    "    \n",
    "    # the total number of attribtues in training data\n",
    "    total_num = sum([len(train_data[i]) for i in train_data.keys()])\n",
    "    \n",
    "    # the prior possibility of each class \n",
    "    prior_class = []\n",
    "    \n",
    "    # a dictionary containing the mean and sd of each attribute from each class \n",
    "    stats = defaultdict(list)\n",
    "    \n",
    "    for i in train_data.keys():\n",
    "        prior_class.append(len(train_data[i])/total_num)\n",
    "        stats[i].append(np.nanmean(train_data[i], axis = 0))\n",
    "        stats[i].append(np.nanstd(train_data[i], axis = 0))\n",
    "\n",
    "    return (train_data, stats, prior_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# a function used to select the best k \n",
    "def select_best_k(train_file, test_file, k_range):\n",
    "    df = pd.read_csv(train_file, na_values = \"9999.0000\", header = None)\n",
    "    df = df.dropna(axis=0, how='all', subset = [i for i in range(1, df.shape[1])])\n",
    "    \n",
    "    # a list of testable k values\n",
    "    k_band = [x for x in range(k_range[0], k_range[1])]\n",
    "    \n",
    "    # a list of accuracy scores obtained by the validation set \n",
    "    scores = []\n",
    "    for k in k_band:\n",
    "        df = shuffle(df)\n",
    "        validation_df = df.head(len(df)//10)\n",
    "        train_df = df[~df.index.isin(validation_df.index)]\n",
    "        train_data, stats, priors = KDE_train(train_df)\n",
    "        y_test, y_pred = KDE_predict(k, stats, priors, validation_df, train_data)\n",
    "        scores.append(evaluate(y_test, y_pred))\n",
    "        \n",
    "    # plot the accuracy perfomance vs different k\n",
    "    fig = plt.figure()\n",
    "    plt.plot(np.array(k_band), np.array(scores), marker = '.')    \n",
    "    plt.xlabel('kernel bandwidth')\n",
    "    plt.ylabel(\"score\")\n",
    "    plt.title(\"Kernel Bandwidth Performance Comparison\")\n",
    "    fig.savefig('figure1.png')\n",
    "    \n",
    "    # select the k value that maximizes accuracy score\n",
    "    best_k_index = 0\n",
    "    for i in scores:\n",
    "        if i == max(scores):\n",
    "            best_k_index = scores.index(i)\n",
    "            break\n",
    "\n",
    "    best_k = k_band[best_k_index]\n",
    "    return best_k\n",
    "\n",
    "print(select_best_k(\"train.csv\", \"test.csv\", (0, 30)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy score using the test file \n",
    "train_df = pd.read_csv(\"train.csv\", na_values = \"9999.0000\", header = None)\n",
    "train_df = train_df.dropna(axis=0, how='all', subset = [i for i in range(1, train_df.shape[1])])\n",
    "test_df = pd.read_csv(\"test.csv\", na_values = \"9999.0000\", header = None)\n",
    "train_data, stats, priors = KDE_train(train_df)\n",
    "y_test, y_pred = KDE_predict(best_k, stats, priors, test_df, train_data)\n",
    "accuracy = evaluate(y_test, y_pred)\n",
    "# print(accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
